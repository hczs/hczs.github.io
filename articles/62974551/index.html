<!DOCTYPE html><html lang="zh"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="HandheldFriendly" content="True"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=5"><meta name="description" content="本地虚拟环境搭建 Hadoop 集群，是集群搭建的过程记录"><meta property="og:type" content="article"><meta property="og:title" content="Hadoop集群搭建"><meta property="og:url" content="https://www.powercheng.fun/articles/62974551/index.html"><meta property="og:site_name" content="Caiden&#39;s Blog"><meta property="og:description" content="本地虚拟环境搭建 Hadoop 集群，是集群搭建的过程记录"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://www.powercheng.fun/articles/62974551/12283FBd7Dimage-20220418151212376.png"><meta property="og:image" content="https://www.powercheng.fun/articles/62974551/C89Dbae1c9image-20220418151414780.png"><meta property="og:image" content="https://www.powercheng.fun/articles/62974551/98fBfA7d99image-20220418151450392.png"><meta property="og:image" content="https://www.powercheng.fun/articles/62974551/bC6293c3Cfimage-20220418151601102.png"><meta property="og:image" content="https://www.powercheng.fun/articles/62974551/fbC70ab4D1image-20220418151620796.png"><meta property="og:image" content="https://www.powercheng.fun/articles/62974551/2CD62cdDBBimage-20220418151737994.png"><meta property="og:image" content="https://www.powercheng.fun/articles/62974551/7619C7D19Cimage-20220418162502644.png"><meta property="og:image" content="https://www.powercheng.fun/articles/62974551/8B5d68A73bimage-20220418162544750.png"><meta property="og:image" content="https://www.powercheng.fun/articles/62974551/411Ca6e1EEimage-20220419103027136.png"><meta property="og:image" content="https://www.powercheng.fun/articles/62974551/6eb0BF980aimage-20220419103102319.png"><meta property="og:image" content="https://www.powercheng.fun/articles/62974551/268dacFC04image-20220419103601551.png"><meta property="og:image" content="https://www.powercheng.fun/articles/62974551/edaf3d0EBDimage-20220419103732990.png"><meta property="og:image" content="https://www.powercheng.fun/articles/62974551/aBCdEdd7C6image-20220419104420931.png"><meta property="og:image" content="https://www.powercheng.fun/articles/62974551/5d6A08d68dimage-20220419104623985.png"><meta property="og:image" content="https://www.powercheng.fun/articles/62974551/1c7c1A14Acimage-20220419104755745.png"><meta property="article:published_time" content="2022-04-18T06:13:16.000Z"><meta property="article:modified_time" content="2025-11-19T03:04:36.787Z"><meta property="article:author" content="Caiden Hou"><meta property="article:tag" content="Hadoop"><meta property="article:tag" content="大数据"><meta property="article:tag" content="环境搭建"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://www.powercheng.fun/articles/62974551/12283FBd7Dimage-20220418151212376.png"><link rel="shortcut icon" href="/images/favicon.ico"><link rel="icon" type="image/png" href="/images/favicon-192x192.png" sizes="192x192"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="stylesheet" href="https://gw.alipayobjects.com/os/k/font/lxgwwenkaiscreenr.css"><title>Hadoop集群搭建</title><link rel="stylesheet" href="/css/style.css"><link rel="alternate" href="/true" title="Caiden&#39;s Blog" type="application/atom+xml"><meta name="generator" content="Hexo 5.4.0"></head><body class="max-width mx-auto px3 ltr"><div id="header-post"><a id="menu-icon" href="#" aria-label="目录"><i class="fa-solid fa-bars fa-lg"></i></a> <a id="menu-icon-tablet" href="#" aria-label="目录"><i class="fa-solid fa-bars fa-lg"></i></a> <a id="top-icon-tablet" href="#" aria-label="顶部" onclick='$("html, body").animate({scrollTop:0},"fast")' style="display:none"><i class="fa-solid fa-chevron-up fa-lg"></i></a> <span id="menu"><span id="nav"><ul><li><a href="/">首页</a></li><li><a href="/archives/">文章</a></li><li><a href="/categories/">分类</a></li><li><a href="/search/">搜索</a></li><li><a href="/about/">关于</a></li></ul></span><br><span id="actions"><ul><li><a class="icon" aria-label="上一篇" href="/articles/edbb2e9c/"><i class="fa-solid fa-chevron-left" aria-hidden="true" onmouseover='$("#i-prev").toggle()' onmouseout='$("#i-prev").toggle()'></i></a></li><li><a class="icon" aria-label="下一篇" href="/articles/1572aa20/"><i class="fa-solid fa-chevron-right" aria-hidden="true" onmouseover='$("#i-next").toggle()' onmouseout='$("#i-next").toggle()'></i></a></li><li><a class="icon" aria-label="返回顶部" href="#" onclick='$("html, body").animate({scrollTop:0},"fast")'><i class="fa-solid fa-chevron-up" aria-hidden="true" onmouseover='$("#i-top").toggle()' onmouseout='$("#i-top").toggle()'></i></a></li><li><a class="icon" aria-label="分享文章" href="#"><i class="fa-solid fa-share-alt" aria-hidden="true" onmouseover='$("#i-share").toggle()' onmouseout='$("#i-share").toggle()' onclick='return $("#share").toggle(),!1'></i></a></li></ul><span id="i-prev" class="info" style="display:none">上一篇</span> <span id="i-next" class="info" style="display:none">下一篇</span> <span id="i-top" class="info" style="display:none">返回顶部</span> <span id="i-share" class="info" style="display:none">分享文章</span></span><br><div id="share" style="display:none"><ul><li><a class="icon" target="_blank" rel="noopener external nofollow noreferrer" href="http://www.facebook.com/sharer.php?u=https://www.powercheng.fun/articles/62974551/"><i class="fab fa-facebook" aria-hidden="true"></i></a></li><li><a class="icon" target="_blank" rel="noopener external nofollow noreferrer" href="https://twitter.com/share?url=https://www.powercheng.fun/articles/62974551/&text=Hadoop集群搭建"><i class="fab fa-twitter" aria-hidden="true"></i></a></li><li><a class="icon" target="_blank" rel="noopener external nofollow noreferrer" href="http://www.linkedin.com/shareArticle?url=https://www.powercheng.fun/articles/62974551/&title=Hadoop集群搭建"><i class="fab fa-linkedin" aria-hidden="true"></i></a></li><li><a class="icon" target="_blank" rel="noopener external nofollow noreferrer" href="https://pinterest.com/pin/create/bookmarklet/?url=https://www.powercheng.fun/articles/62974551/&is_video=false&description=Hadoop集群搭建"><i class="fab fa-pinterest" aria-hidden="true"></i></a></li><li><a class="icon" href="mailto:?subject=Hadoop集群搭建&body=Check out this article: https://www.powercheng.fun/articles/62974551/" rel="external nofollow noreferrer"><i class="fa-solid fa-envelope" aria-hidden="true"></i></a></li><li><a class="icon" target="_blank" rel="noopener external nofollow noreferrer" href="https://getpocket.com/save?url=https://www.powercheng.fun/articles/62974551/&title=Hadoop集群搭建"><i class="fab fa-get-pocket" aria-hidden="true"></i></a></li><li><a class="icon" target="_blank" rel="noopener external nofollow noreferrer" href="http://reddit.com/submit?url=https://www.powercheng.fun/articles/62974551/&title=Hadoop集群搭建"><i class="fab fa-reddit" aria-hidden="true"></i></a></li><li><a class="icon" target="_blank" rel="noopener external nofollow noreferrer" href="http://www.stumbleupon.com/submit?url=https://www.powercheng.fun/articles/62974551/&title=Hadoop集群搭建"><i class="fab fa-stumbleupon" aria-hidden="true"></i></a></li><li><a class="icon" target="_blank" rel="noopener external nofollow noreferrer" href="http://digg.com/submit?url=https://www.powercheng.fun/articles/62974551/&title=Hadoop集群搭建"><i class="fab fa-digg" aria-hidden="true"></i></a></li><li><a class="icon" target="_blank" href="http://www.tumblr.com/share/link?url=https://www.powercheng.fun/articles/62974551/&name=Hadoop集群搭建&description=&lt;link rel=&#34;stylesheet&#34; type=&#34;text/css&#34; href=&#34;https://cdn.jsdelivr.net/lightgallery.js/1.0.1/css/lightgallery.min.css&#34; /&gt;&lt;div class=&#34;.article-gallery&#34;&gt;&lt;p&gt;本地虚拟环境搭建 Hadoop 集群，是集群搭建的过程记录&lt;/p&gt;"><i class="fab fa-tumblr" aria-hidden="true"></i></a></li><li><a class="icon" target="_blank" rel="noopener external nofollow noreferrer" href="https://news.ycombinator.com/submitlink?u=https://www.powercheng.fun/articles/62974551/&t=Hadoop集群搭建"><i class="fab fa-hacker-news" aria-hidden="true"></i></a></li></ul></div><div id="toc"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B4%E4%BD%93%E6%B5%81%E7%A8%8B"><span class="toc-number">1.</span> <span class="toc-text">整体流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E6%9D%BF%E6%9C%BA%E5%87%86%E5%A4%87"><span class="toc-number">2.</span> <span class="toc-text">模板机准备</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%85%8D%E7%BD%AE"><span class="toc-number">2.1.</span> <span class="toc-text">虚拟机配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E5%8C%BA%E9%85%8D%E7%BD%AE"><span class="toc-number">2.2.</span> <span class="toc-text">分区配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E5%8F%8A%E4%B8%BB%E6%9C%BA%E5%90%8D%E9%85%8D%E7%BD%AE"><span class="toc-number">2.3.</span> <span class="toc-text">网络及主机名配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#epel-release-%E5%AE%89%E8%A3%85"><span class="toc-number">2.4.</span> <span class="toc-text">epel-release 安装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B3%E9%97%AD%E9%98%B2%E7%81%AB%E5%A2%99"><span class="toc-number">2.5.</span> <span class="toc-text">关闭防火墙</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85%E7%9B%AE%E5%BD%95%E5%92%8C%E5%AE%89%E8%A3%85%E5%8C%85%E5%AD%98%E6%94%BE%E7%9B%AE%E5%BD%95"><span class="toc-number">2.6.</span> <span class="toc-text">创建软件安装目录和安装包存放目录</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%B8%E8%BD%BD%E8%99%9A%E6%8B%9F%E6%9C%BA%E8%87%AA%E5%B8%A6-JDK"><span class="toc-number">2.7.</span> <span class="toc-text">卸载虚拟机自带 JDK</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA"><span class="toc-number">3.</span> <span class="toc-text">集群搭建</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E6%A8%A1%E6%9D%BF%E6%9C%BA%E5%85%8B%E9%9A%86%E5%87%BA%E4%B8%89%E5%8F%B0%E6%9C%BA%E5%99%A8%E5%81%9A%E9%9B%86%E7%BE%A4"><span class="toc-number">3.1.</span> <span class="toc-text">使用模板机克隆出三台机器做集群</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9-ip-%E5%92%8C-hostname"><span class="toc-number">3.2.</span> <span class="toc-text">修改 ip 和 hostname</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE-hosts"><span class="toc-number">3.3.</span> <span class="toc-text">配置 hosts</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#JDK-%E5%AE%89%E8%A3%85"><span class="toc-number">3.4.</span> <span class="toc-text">JDK 安装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hadoop-%E5%AE%89%E8%A3%85"><span class="toc-number">3.5.</span> <span class="toc-text">Hadoop 安装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE-ssh-%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95"><span class="toc-number">3.6.</span> <span class="toc-text">配置 ssh 免密登录</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%96%E5%86%99-xsync-%E5%88%86%E5%8F%91%E8%84%9A%E6%9C%AC"><span class="toc-number">3.7.</span> <span class="toc-text">编写 xsync 分发脚本</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E5%8F%91%E5%B7%B2%E5%AE%89%E8%A3%85%E7%9A%84-JDK-%E5%92%8C-Hadoop"><span class="toc-number">3.8.</span> <span class="toc-text">分发已安装的 JDK 和 Hadoop</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E8%A7%84%E5%88%92"><span class="toc-number">3.9.</span> <span class="toc-text">集群部署规划</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE-Hadoop-%E7%9B%B8%E5%85%B3%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">3.10.</span> <span class="toc-text">配置 Hadoop 相关配置文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E5%8F%91-%E5%90%8C%E6%AD%A5-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">3.11.</span> <span class="toc-text">分发&#x2F;同步 配置文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9D%E5%A7%8B%E5%8C%96%E9%9B%86%E7%BE%A4"><span class="toc-number">3.12.</span> <span class="toc-text">初始化集群</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8-HDFS-%E5%8F%8A-YARN"><span class="toc-number">3.13.</span> <span class="toc-text">启动 HDFS 及 YARN</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%AA%8C%E8%AF%81%E5%8F%8A%E6%B5%8B%E8%AF%95"><span class="toc-number">3.14.</span> <span class="toc-text">验证及测试</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%80%9A%E8%BF%87%E6%9F%A5%E7%9C%8B%E5%90%8E%E5%8F%B0%E8%BF%9B%E7%A8%8B%E9%AA%8C%E8%AF%81-HDFS-%E5%8F%8A-YARN-%E6%98%AF%E5%90%A6%E6%88%90%E5%8A%9F%E5%90%AF%E5%8A%A8"><span class="toc-number">3.14.1.</span> <span class="toc-text">通过查看后台进程验证 HDFS 及 YARN 是否成功启动</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8E%BB-web-%E7%95%8C%E9%9D%A2%E6%9F%A5%E7%9C%8B"><span class="toc-number">3.14.2.</span> <span class="toc-text">去 web 界面查看</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6%E5%88%B0-HDFS-%E6%B5%8B%E8%AF%95"><span class="toc-number">3.14.3.</span> <span class="toc-text">上传文件到 HDFS 测试</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#MapReduce-%E6%B5%8B%E8%AF%95"><span class="toc-number">3.14.4.</span> <span class="toc-text">MapReduce 测试</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%B3%E6%AD%A4%EF%BC%8C%E9%9B%86%E7%BE%A4%E5%B7%B2%E6%90%AD%E5%BB%BA%E5%AE%8C%E6%88%90"><span class="toc-number">3.15.</span> <span class="toc-text">至此，集群已搭建完成</span></a></li></ol></li></ol></div></span></div><div class="content index py4"><article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting"><header><h1 class="posttitle p-name" itemprop="name headline">Hadoop集群搭建</h1><div class="meta"><div class="postdate"><time datetime="2022-04-18T06:13:16.000Z" class="dt-published" itemprop="datePublished">2022-04-18</time> (Updated: <time datetime="2025-11-19T03:04:36.787Z" class="dt-updated" itemprop="dateModified">2025-11-19</time>)</div><div class="article-category"><i class="fa-solid fa-archive"></i> <a class="category-link" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></div><div class="article-tag"><i class="fa-solid fa-tag"></i> <a class="p-category" href="/tags/Hadoop/" rel="tag">Hadoop</a>, <a class="p-category" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag">大数据</a>, <a class="p-category" href="/tags/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/" rel="tag">环境搭建</a></div></div></header><div class="content e-content" itemprop="articleBody"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/lightgallery.js/1.0.1/css/lightgallery.min.css"><div class=".article-gallery"><p>本地虚拟环境搭建 Hadoop 集群，是集群搭建的过程记录</p><span id="more"></span><h2 id="整体流程"><a href="#整体流程" class="headerlink" title="整体流程"></a>整体流程</h2><p>基于 CentOS7.5、JDK1.8、Hadoop3.1.3 搭建</p><ol><li>准备一台模板机，模板机需要配置好以下内容<ul><li>网络、主机名配置</li><li>epel-release 安装（Extra Packages for Enterprise Linux 是为“红帽系”的操作系统提供额外的软件包， 适用于 RHEL、CentOS 和 Scientific Linux。相当于是一个软件仓库，大多数 rpm 包在官方 repository 中是找不到的）</li><li>因为是本地测试环境，所以直接把防火墙关闭，并且关闭防火墙开机自启动，以后就不用单独开端口了</li><li>在 opt 下创建文件夹<ul><li>/opt/software：存放软件安装包</li><li>/opt/module：软件安装目录，所有软件都安装到这里</li></ul></li><li>卸载虚拟机自带 JDK</li><li>磁盘分区<ul><li>/boot: 1024 MB</li><li>/ : 45 G</li><li>/swap: 4096 MB</li></ul></li></ul></li><li>然后通过这台模板机，克隆三台虚拟机做集群搭建</li><li>三台虚拟机分别修改ip、host，配置 hosts</li><li>一台虚拟机安装 JDK 和 Hadoop ，并配置环境变量</li><li>配置 ssh 免密登录</li><li>编写 xsync 分发脚本，将内容分发到另外两台机器</li><li>配置 Hadoop 相关配置文件</li><li>同步分发配置好的配置文件，初始化集群、启动 HDFS、启动 YARN</li><li>测试验证<ul><li>存取文件</li><li>MapReduce 计算任务提交</li></ul></li></ol><h2 id="模板机准备"><a href="#模板机准备" class="headerlink" title="模板机准备"></a>模板机准备</h2><h3 id="虚拟机配置"><a href="#虚拟机配置" class="headerlink" title="虚拟机配置"></a>虚拟机配置</h3><p>几个重要参数，需要根据自己实际情况来：</p><ol><li>内存：我本地是 16G，所以 一台机器 2G 是没问题的，一共就是 2 * 3 = 6 G</li><li>处理器：我本地是 4 核 8 线程，所以一台机器 2 个 cpu，一共就是 2 * 3 = 6 C</li><li>硬盘：最低 50 G</li><li>操作系统：CentOS7.5</li><li>网络适配器：NAT</li></ol><a href="/articles/62974551/12283FBd7Dimage-20220418151212376.png" class="gallery-item"><img src="/articles/62974551/12283FBd7Dimage-20220418151212376.png" title="image-20220418151212376"></a><h3 id="分区配置"><a href="#分区配置" class="headerlink" title="分区配置"></a>分区配置</h3><ul><li>/boot: 1024 MB</li><li>/ : 45 G</li><li>/swap: 4096 MB</li></ul><p>具体如何设置如下图步骤</p><a href="/articles/62974551/C89Dbae1c9image-20220418151414780.png" class="gallery-item"><img src="/articles/62974551/C89Dbae1c9image-20220418151414780.png" title="image-20220418151414780"></a><p>​ <a href="/articles/62974551/98fBfA7d99image-20220418151450392.png" class="gallery-item"><img src="/articles/62974551/98fBfA7d99image-20220418151450392.png" title="image-20220418151450392"></a></p><a href="/articles/62974551/bC6293c3Cfimage-20220418151601102.png" class="gallery-item"><img src="/articles/62974551/bC6293c3Cfimage-20220418151601102.png" title="image-20220418151601102"></a><a href="/articles/62974551/fbC70ab4D1image-20220418151620796.png" class="gallery-item"><img src="/articles/62974551/fbC70ab4D1image-20220418151620796.png" title="image-20220418151620796"></a><a href="/articles/62974551/2CD62cdDBBimage-20220418151737994.png" class="gallery-item"><img src="/articles/62974551/2CD62cdDBBimage-20220418151737994.png" title="image-20220418151737994"></a><h3 id="网络及主机名配置"><a href="#网络及主机名配置" class="headerlink" title="网络及主机名配置"></a>网络及主机名配置</h3><p>IP 网段查看：虚拟机主界面 -&gt; 编辑 -&gt; 虚拟网络编辑器 -&gt; 找到 NAT 模式的子网 IP</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 切换到root用户</span></span><br><span class="line">su root</span><br><span class="line"><span class="meta">#</span><span class="bash"> 编辑网卡配置</span></span><br><span class="line">vim /etc/sysconfig/network-scripts/ifcfg-ens33</span><br><span class="line"><span class="meta">#</span><span class="bash"> 改动</span></span><br><span class="line">BOOTPROTO=static</span><br><span class="line"><span class="meta">#</span><span class="bash"> 新增</span></span><br><span class="line">IPADDR=192.168.3.100</span><br><span class="line">NETMASK=255.255.255.0</span><br><span class="line">GATEWAY=192.168.3.2</span><br><span class="line">DNS1=114.114.114.114</span><br><span class="line"><span class="meta">#</span><span class="bash"> 重启网络</span></span><br><span class="line">service network restart</span><br><span class="line"><span class="meta">#</span><span class="bash"> 验证</span></span><br><span class="line">ping baidu.com</span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置主机名 hostname</span></span><br><span class="line">vim /etc/hostname</span><br><span class="line"><span class="meta">#</span><span class="bash"> 重启 使用 hostname 命令查看是否生效</span></span><br><span class="line">hostname</span><br></pre></td></tr></table></figure><h3 id="epel-release-安装"><a href="#epel-release-安装" class="headerlink" title="epel-release 安装"></a>epel-release 安装</h3><p>Extra Packages for Enterprise Linux 是为“红帽系”的操作系统提供额外的软件包， 适用于 RHEL、CentOS 和 Scientific Linux。相当于是一个软件仓库，大多数 rpm 包在官方 repository 中是找不到的</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y epel-release</span><br></pre></td></tr></table></figure><h3 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 关闭防火墙</span></span><br><span class="line">[root@hadoop100 ~]# systemctl stop firewalld</span><br><span class="line"><span class="meta">#</span><span class="bash"> 关闭开机自启</span></span><br><span class="line">[root@hadoop100 ~]# systemctl disable firewalld.service</span><br></pre></td></tr></table></figure><h3 id="创建软件安装目录和安装包存放目录"><a href="#创建软件安装目录和安装包存放目录" class="headerlink" title="创建软件安装目录和安装包存放目录"></a>创建软件安装目录和安装包存放目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 软件包存放目录</span></span><br><span class="line">[root@hadoop100 ~]# mkdir /opt/software</span><br><span class="line"><span class="meta">#</span><span class="bash"> 软件安装目录</span></span><br><span class="line">[root@hadoop100 ~]# mkdir /opt/module</span><br></pre></td></tr></table></figure><h3 id="卸载虚拟机自带-JDK"><a href="#卸载虚拟机自带-JDK" class="headerlink" title="卸载虚拟机自带 JDK"></a>卸载虚拟机自带 JDK</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm -qa | grep -i java | xargs -n1 rpm -e --nodeps</span><br></pre></td></tr></table></figure><ul><li>rpm -qa：查询已安装的所有 rpm 软件包</li><li>-i：忽略大小写</li><li>xargs -n1：表示每次只传递一个参数</li><li>rpm -e –nodeps：强制卸载软件</li></ul><h2 id="集群搭建"><a href="#集群搭建" class="headerlink" title="集群搭建"></a>集群搭建</h2><h3 id="使用模板机克隆出三台机器做集群"><a href="#使用模板机克隆出三台机器做集群" class="headerlink" title="使用模板机克隆出三台机器做集群"></a>使用模板机克隆出三台机器做集群</h3><p>克隆注意事项：</p><ol><li>要选择完全克隆，而不是克隆一个链接</li><li>克隆之前一定要关闭虚拟机，这里就是关闭 hadoop100 这台机器</li><li>克隆时长和硬盘有关，机械硬盘大概三五分钟，固态的话就是二十多秒</li></ol><p>具体步骤如下</p><a href="/articles/62974551/7619C7D19Cimage-20220418162502644.png" class="gallery-item"><img src="/articles/62974551/7619C7D19Cimage-20220418162502644.png" title="image-20220418162502644"></a><p>一直下一步，然后注意这里要选择创建完整克隆：</p><a href="/articles/62974551/8B5d68A73bimage-20220418162544750.png" class="gallery-item"><img src="/articles/62974551/8B5d68A73bimage-20220418162544750.png" title="image-20220418162544750"></a><h3 id="修改-ip-和-hostname"><a href="#修改-ip-和-hostname" class="headerlink" title="修改 ip 和 hostname"></a>修改 ip 和 hostname</h3><p><strong>依次</strong>配置三台机器的 ip 和 hostname，步骤如下</p><p>只用修改 IPADDR 就行，分别改 102,103,104</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 切换到root用户</span></span><br><span class="line">su root</span><br><span class="line"><span class="meta">#</span><span class="bash"> 编辑网卡配置</span></span><br><span class="line">vim /etc/sysconfig/network-scripts/ifcfg-ens33</span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改行</span></span><br><span class="line">IPADDR=192.168.3.102</span><br><span class="line"><span class="meta">#</span><span class="bash"> 再修改 hostname</span></span><br><span class="line">vim /etc/hostname</span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改完毕后重启</span></span><br><span class="line">reboot</span><br></pre></td></tr></table></figure><h3 id="配置-hosts"><a href="#配置-hosts" class="headerlink" title="配置 hosts"></a>配置 hosts</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/hosts</span><br><span class="line"><span class="meta">#</span><span class="bash"> 在文件中加入以下内容</span></span><br><span class="line">192.168.3.100 hadoop100</span><br><span class="line">192.168.3.102 hadoop102</span><br><span class="line">192.168.3.103 hadoop103</span><br><span class="line">192.168.3.104 hadoop104</span><br><span class="line"><span class="meta">#</span><span class="bash"> 验证 三台机器可以互相ping一下</span></span><br><span class="line">ping hadoop102</span><br><span class="line">ping hadoop103</span><br><span class="line">ping hadoop104</span><br></pre></td></tr></table></figure><p>这里建议在 windows 上也配置上面的 hosts，后面就不用 ip 访问了</p><h3 id="JDK-安装"><a href="#JDK-安装" class="headerlink" title="JDK 安装"></a>JDK 安装</h3><p>首先把 JDK 压缩包上传到 /opt/software 下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 解压到/opt/module/</span></span><br><span class="line">tar -zxvf jdk-8u131-linux-x64.tar.gz -C /opt/module/</span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置环境变量</span></span><br><span class="line">cd /etc/profile.d/</span><br><span class="line"><span class="meta">#</span><span class="bash"> 建一个自己的环境变量描述文件</span></span><br><span class="line">vim my_env.sh</span><br><span class="line"><span class="meta">#</span><span class="bash"> 写入以下内容</span></span><br><span class="line"><span class="meta">#</span><span class="bash">JAVA_HOME</span></span><br><span class="line">export JAVA_HOME=/opt/module/jdk1.8.0_131</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br><span class="line"><span class="meta">#</span><span class="bash"> 重新加载环境变量</span></span><br><span class="line">source /etc/profile</span><br><span class="line"><span class="meta">#</span><span class="bash"> 验证 输出版本信息完成安装</span></span><br><span class="line">java -version</span><br></pre></td></tr></table></figure><h3 id="Hadoop-安装"><a href="#Hadoop-安装" class="headerlink" title="Hadoop 安装"></a>Hadoop 安装</h3><p>首先把 Hadoop 压缩包上传到 /opt/software 下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 解压到/opt/module/</span></span><br><span class="line">tar -zxvf hadoop-3.1.3.tar.gz -C /opt/module/</span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置环境变量</span></span><br><span class="line">vim /etc/profile.d/my_env.sh</span><br><span class="line"><span class="meta">#</span><span class="bash"> 添加以下内容</span></span><br><span class="line"><span class="meta">#</span><span class="bash">HADOOP_HOME</span></span><br><span class="line">export HADOOP_HOME=/opt/module/hadoop-3.1.3</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/sbin</span><br><span class="line"><span class="meta">#</span><span class="bash"> 重新加载</span></span><br><span class="line">source /etc/profile</span><br><span class="line"><span class="meta">#</span><span class="bash"> 验证 有内容输出代表完成安装</span></span><br><span class="line">hadoop</span><br></pre></td></tr></table></figure><h3 id="配置-ssh-免密登录"><a href="#配置-ssh-免密登录" class="headerlink" title="配置 ssh 免密登录"></a>配置 ssh 免密登录</h3><p>这个免密是这三台机器（hadoop102，hadoop103，hadoop104）之间互相 ssh 登录不用密码验证</p><p>三台机器一次执行以下内容</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 切换到 隐藏目录 .ssh 下，在这能方便的看到生成的密钥对 查看隐藏目录的方法 ll -a</span></span><br><span class="line">cd /root/.ssh/</span><br><span class="line"><span class="meta">#</span><span class="bash"> 生成密钥对，输入命令 按三下回车</span></span><br><span class="line">ssh-keygen -t rsa</span><br><span class="line"><span class="meta">#</span><span class="bash"> .pub 就是公钥 第一个就是私钥</span></span><br><span class="line">[root@hadoop102 .ssh]# ll</span><br><span class="line">总用量 12</span><br><span class="line">-rw-------. 1 root root 1675 4月  18 17:24 id_rsa</span><br><span class="line">-rw-r--r--. 1 root root  396 4月  18 17:24 id_rsa.pub</span><br><span class="line">-rw-r--r--. 1 root root  185 4月  18 17:10 known_hosts</span><br><span class="line"><span class="meta">#</span><span class="bash"> 将公钥分发出去，免密登录配置完成</span></span><br><span class="line">ssh-copy-id hadoop102</span><br><span class="line">ssh-copy-id hadoop103</span><br><span class="line">ssh-copy-id hadoop104</span><br></pre></td></tr></table></figure><h3 id="编写-xsync-分发脚本"><a href="#编写-xsync-分发脚本" class="headerlink" title="编写 xsync 分发脚本"></a>编写 xsync 分发脚本</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 进入到 /usr/bin 在这里写的可执行文件可以全局使用 而且任何用户都可用</span></span><br><span class="line">cd /usr/bin</span><br><span class="line"><span class="meta">#</span><span class="bash"> 新建编辑脚本</span></span><br><span class="line">vim xsync</span><br><span class="line"><span class="meta">#</span><span class="bash"> 写入以下内容</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 添加可执行权限</span></span><br><span class="line">chmod +x xsync</span><br><span class="line"><span class="meta">#</span><span class="bash"> 把 xsync 分发到另外两台机器</span></span><br><span class="line">xsync xsync</span><br><span class="line"><span class="meta">#</span><span class="bash"> 同步过程内容</span></span><br><span class="line">[root@hadoop102 bin]# xsync xsync</span><br><span class="line">==================== hadoop102 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line"></span><br><span class="line">sent 44 bytes  received 12 bytes  37.33 bytes/sec</span><br><span class="line">total size is 740  speedup is 13.21</span><br><span class="line">==================== hadoop103 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line">xsync</span><br><span class="line"></span><br><span class="line">sent 831 bytes  received 35 bytes  577.33 bytes/sec</span><br><span class="line">total size is 740  speedup is 0.85</span><br><span class="line">==================== hadoop104 ====================</span><br><span class="line">sending incremental file list</span><br><span class="line">xsync</span><br><span class="line"></span><br><span class="line">sent 831 bytes  received 35 bytes  577.33 bytes/sec</span><br><span class="line">total size is 740  speedup is 0.85</span><br></pre></td></tr></table></figure><p>xsync 脚本内容</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">1. 判断参数个数</span></span><br><span class="line">if [ $# -lt 1 ]</span><br><span class="line">then</span><br><span class="line">    echo Not Enough Arguement!</span><br><span class="line">    exit;</span><br><span class="line">fi</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">2. 遍历集群所有机器</span></span><br><span class="line">for host in hadoop102 hadoop103 hadoop104</span><br><span class="line">do</span><br><span class="line">    echo ====================  $host  ====================</span><br><span class="line">    #3. 遍历所有目录，挨个发送</span><br><span class="line"></span><br><span class="line">    for file in $@</span><br><span class="line">    do</span><br><span class="line">        #4. 判断文件是否存在</span><br><span class="line">        if [ -e $file ]</span><br><span class="line">            then</span><br><span class="line">                #5. 获取父目录</span><br><span class="line">                pdir=$(cd -P $(dirname $file); pwd)</span><br><span class="line"></span><br><span class="line">                #6. 获取当前文件的名称</span><br><span class="line">                fname=$(basename $file)</span><br><span class="line">                ssh $host &quot;mkdir -p $pdir&quot;</span><br><span class="line">                rsync -av $pdir/$fname $host:$pdir</span><br><span class="line">            else</span><br><span class="line">                echo $file does not exists!</span><br><span class="line">        fi</span><br><span class="line">    done</span><br><span class="line">done</span><br></pre></td></tr></table></figure><p>脚本使用，脚本后面可以跟文件/目录，然后三台机器都会把这个文件（目录）同步到相同的内容</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 进入 opt 创建一个 test.txt</span></span><br><span class="line">cd /opt</span><br><span class="line">vim test.txt</span><br><span class="line"><span class="meta">#</span><span class="bash"> 随便写入点内容，然后同步</span></span><br><span class="line">xsync test.txt</span><br><span class="line"><span class="meta">#</span><span class="bash"> 进入到其他机器上，可以看到 opt 下已经有了这个 txt 文件了</span></span><br><span class="line">[root@hadoop103 ~]# cd /opt/</span><br><span class="line">[root@hadoop103 opt]# ll</span><br><span class="line">总用量 4</span><br><span class="line">drwxr-xr-x. 2 root root 6 4月  18 16:19 module</span><br><span class="line">drwxr-xr-x. 2 root root 6 9月   7 2017 rh</span><br><span class="line">drwxr-xr-x. 2 root root 6 4月  18 16:19 software</span><br><span class="line">-rw-r--r--. 1 root root 6 4月  18 20:18 test.txt</span><br><span class="line">[root@hadoop103 opt]# cat test.txt</span><br><span class="line">hello</span><br></pre></td></tr></table></figure><h3 id="分发已安装的-JDK-和-Hadoop"><a href="#分发已安装的-JDK-和-Hadoop" class="headerlink" title="分发已安装的 JDK 和 Hadoop"></a>分发已安装的 JDK 和 Hadoop</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 直接同步 opt 目录</span></span><br><span class="line">xsync /opt/</span><br><span class="line"><span class="meta">#</span><span class="bash"> 再同步环境变量</span></span><br><span class="line">xsync /etc/profile.d/my_env.sh</span><br><span class="line"><span class="meta">#</span><span class="bash"> 去另外两台机器上，重新加载环境变量</span></span><br><span class="line">source /etc/profile</span><br><span class="line"><span class="meta">#</span><span class="bash"> 验证</span></span><br><span class="line">java -version</span><br><span class="line">hadoop</span><br></pre></td></tr></table></figure><h3 id="集群部署规划"><a href="#集群部署规划" class="headerlink" title="集群部署规划"></a>集群部署规划</h3><p>注意点：</p><ol><li>NameNode 和 SecondaryNameNode 不要安装在同一台服务器，不然一个挂全挂了，起不到 2nn 的作用</li><li>ResourceManager 也很消耗内存，不要和 NameNode、SecondaryNameNode 配置在同一台机器上。</li></ol><table><thead><tr><th></th><th>hadoop102</th><th>hadoop103</th><th>hadoop104</th></tr></thead><tbody><tr><td>HDFS</td><td>NameNode、DataNode</td><td>DataNode</td><td>SecondaryNameNode、DataNode</td></tr><tr><td>YARN</td><td>NodeManager</td><td>ResourceManager、NodeManager</td><td>NodeManager</td></tr></tbody></table><h3 id="配置-Hadoop-相关配置文件"><a href="#配置-Hadoop-相关配置文件" class="headerlink" title="配置 Hadoop 相关配置文件"></a>配置 Hadoop 相关配置文件</h3><p>core-site.xml、hdfs-site.xml、yarn-site.xml、mapred-site.xml 四个配置文件存放在<code>$HADOOP_HOME/etc/hadoop</code>这个路径上，用户可以根据项目需求重新进行修改配置。</p><ol><li><p>核心配置文件 core-site.xml</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 进入配置文件目录，编写配置文件</span></span><br><span class="line">cd /opt/module/hadoop-3.1.3/etc/hadoop</span><br><span class="line">vim core-site.xml</span><br></pre></td></tr></table></figure><p>配置文件内容，主要是指定 NameNode 的地址，也就是规划好的 hadoop102，还有就是指定存储目录，因为默认目录是存储在 /tmp 下的，/tmp 只是个临时目录</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定NameNode的地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop102:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 指定hadoop数据的存储目录 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-3.1.3/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>HDFS 配置文件 hdfs-site.xml</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim hdfs-site.xml</span><br></pre></td></tr></table></figure><p>配置文件内容：配置可视化 web 地址，通过这个可以直接在 web 端查看集群存储情况</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- nn web端访问地址--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:9870<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 2nn web端访问地址--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop104:9868<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>YARN 配置文件 yarn-site.xml</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim yarn-site.xml</span><br></pre></td></tr></table></figure><p>配置文件内容：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot;?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Site specific YARN configuration properties --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定MR走shuffle --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 指定ResourceManager的地址--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop103<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 环境变量的继承 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.env-whitelist<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>MapReduce 配置文件 mapred-site.xml</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim mapred-site.xml</span><br></pre></td></tr></table></figure><p>配置文件内容，这里配置 MapReduce 运行内存，为非必要项，但是在跑 MapReduce 程序时候可能会出现内存不足的情况，所以这里加了配置</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定MapReduce程序运行在Yarn上 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 配置 MapReduce 运行内存 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.memory.mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>4096<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.memory.mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>4096<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>因为我使用的是 root 用户，所以还要额外配置一个配置文件 <code>$HADOOP_HOME/etc/hadoop/hadoop-env.sh</code>，在文件末尾添加以下内容</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">export HDFS_NAMENODE_USER=&quot;root&quot;</span><br><span class="line">export HDFS_DATANODE_USER=&quot;root&quot;</span><br><span class="line">export HDFS_SECONDARYNAMENODE_USER=&quot;root&quot;</span><br><span class="line">export YARN_RESOURCEMANAGER_USER=&quot;root&quot;</span><br><span class="line">export YARN_NODEMANAGER_USER=&quot;root&quot;</span><br></pre></td></tr></table></figure><p>如果不配置的话，启动集群的时候就会报错：<code>but there is no HDFS_NAMENODE_USER defined. Aborting operation.</code></p><p>参考：<a target="_blank" rel="noopener external nofollow noreferrer" href="https://stackoverflow.com/questions/48129029/hdfs-namenode-user-hdfs-datanode-user-hdfs-secondarynamenode-user-not-defined">https://stackoverflow.com/questions/48129029/hdfs-namenode-user-hdfs-datanode-user-hdfs-secondarynamenode-user-not-defined</a></p></li><li><p>「重要」配置 workers</p><p>不配置这个，没法群起集群，不然 hadoop 都不知道有几台机器能用</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/module/hadoop-3.1.3/etc/hadoop</span><br><span class="line">vim workers</span><br><span class="line"><span class="meta">#</span><span class="bash"> 把localhost 删掉，添加以下内容，注意，这个里面不允许有空格 空行这些</span></span><br><span class="line">hadoop102</span><br><span class="line">hadoop103</span><br><span class="line">hadoop104</span><br></pre></td></tr></table></figure></li></ol><h3 id="分发-同步-配置文件"><a href="#分发-同步-配置文件" class="headerlink" title="分发/同步 配置文件"></a>分发/同步 配置文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 进入 hadoop 目录，同步</span></span><br><span class="line">cd /opt/module/hadoop-3.1.3</span><br><span class="line">xsync etc/</span><br></pre></td></tr></table></figure><h3 id="初始化集群"><a href="#初始化集群" class="headerlink" title="初始化集群"></a>初始化集群</h3><p>注意：只有集群是第一次启动才需要此操作，并且要在 hadoop102 上格式化 NameNode</p><p>格式化NameNode，会产生新的集群id，导致NameNode和DataNode的集群id不一致，集群找不到已往数据。如果集群在运行过程中报错，需要重新格式化NameNode的话，一定要先停止namenode和datanode进程，并且要删除所有机器的data和logs目录，然后再进行格式化</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -format</span><br></pre></td></tr></table></figure><h3 id="启动-HDFS-及-YARN"><a href="#启动-HDFS-及-YARN" class="headerlink" title="启动 HDFS 及 YARN"></a>启动 HDFS 及 YARN</h3><p>在 hadoop102 上启动集群</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/module/hadoop-3.1.3/sbin</span><br><span class="line">start-dfs.sh</span><br></pre></td></tr></table></figure><p>在配置了 ResourceManager 的机器上（hadoop103） 上启动 YARN</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/module/hadoop-3.1.3/sbin</span><br><span class="line">start-yarn.sh</span><br></pre></td></tr></table></figure><h3 id="验证及测试"><a href="#验证及测试" class="headerlink" title="验证及测试"></a>验证及测试</h3><h4 id="通过查看后台进程验证-HDFS-及-YARN-是否成功启动"><a href="#通过查看后台进程验证-HDFS-及-YARN-是否成功启动" class="headerlink" title="通过查看后台进程验证 HDFS 及 YARN 是否成功启动"></a>通过查看后台进程验证 HDFS 及 YARN 是否成功启动</h4><p>可以看到确实是按照部署规划完成部署，hadoop102 是 nn，hadoop103 是 rm，hadoop104 是 2nn</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 在三台机器上分别输入 jps 查看</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> hadoop102</span></span><br><span class="line">[root@hadoop102 sbin]# jps</span><br><span class="line">15040 DataNode</span><br><span class="line">14840 NameNode</span><br><span class="line">15464 NodeManager</span><br><span class="line">15579 Jps</span><br><span class="line"><span class="meta">#</span><span class="bash"> hadoop103</span></span><br><span class="line">[root@hadoop103 sbin]# jps</span><br><span class="line">13926 NodeManager</span><br><span class="line">14374 Jps</span><br><span class="line">13741 ResourceManager</span><br><span class="line">13423 DataNode</span><br><span class="line"><span class="meta">#</span><span class="bash"> hadoop104</span></span><br><span class="line">[root@hadoop104 ~]# jps</span><br><span class="line">3395 NodeManager</span><br><span class="line">3157 DataNode</span><br><span class="line">3541 Jps</span><br><span class="line">3241 SecondaryNameNode</span><br></pre></td></tr></table></figure><h4 id="去-web-界面查看"><a href="#去-web-界面查看" class="headerlink" title="去 web 界面查看"></a>去 web 界面查看</h4><ul><li><p>到 HDFS 上查看集群节点情况：<a target="_blank" rel="noopener external nofollow noreferrer" href="http://hadoop102:9870/dfshealth.html#tab-datanode">http://hadoop102:9870/dfshealth.html#tab-datanode</a></p><a href="/articles/62974551/411Ca6e1EEimage-20220419103027136.png" class="gallery-item"><img src="/articles/62974551/411Ca6e1EEimage-20220419103027136.png" title="image-20220419103027136"></a></li><li><p>到 YARN 上查看集群节点情况：<a target="_blank" rel="noopener external nofollow noreferrer" href="http://hadoop103:8088/cluster/nodes">http://hadoop103:8088/cluster/nodes</a></p><a href="/articles/62974551/6eb0BF980aimage-20220419103102319.png" class="gallery-item"><img src="/articles/62974551/6eb0BF980aimage-20220419103102319.png" title="image-20220419103102319"></a></li></ul><h4 id="上传文件到-HDFS-测试"><a href="#上传文件到-HDFS-测试" class="headerlink" title="上传文件到 HDFS 测试"></a>上传文件到 HDFS 测试</h4><ol><li><p>在 HDFS 根目录下建一个 wcinput 目录</p><p>语法：<code>hadoop fs -mkdir [path]</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mkdir /wcinput</span><br></pre></td></tr></table></figure></li><li><p>把本地文件上传到 HDFS 上</p><p>语法：<code>hadoop fs -put [source] [dest]</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 编辑一个 word.txt 文件做分词使用</span></span><br><span class="line">vim word.txt</span><br><span class="line"><span class="meta">#</span><span class="bash"> 写入测试内容，随意</span></span><br><span class="line">houge houge</span><br><span class="line">cheng</span><br><span class="line">ceshi ceshi ceshi</span><br><span class="line"><span class="meta">#</span><span class="bash"> 上传到 HDFS 根目录下的 wcinput 文件夹中</span></span><br><span class="line">hadoop fs -put word.txt /wcinput</span><br></pre></td></tr></table></figure></li><li><p>再往 HDFS 的根目录下传一个大一点的文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/software</span><br><span class="line">hadoop fs -put jdk-8u131-linux-x64.tar.gz /</span><br></pre></td></tr></table></figure></li><li><p>到 web 端查看是否上传成功</p><a href="/articles/62974551/268dacFC04image-20220419103601551.png" class="gallery-item"><img src="/articles/62974551/268dacFC04image-20220419103601551.png" title="image-20220419103601551"></a><p>查看 word.txt</p><a href="/articles/62974551/edaf3d0EBDimage-20220419103732990.png" class="gallery-item"><img src="/articles/62974551/edaf3d0EBDimage-20220419103732990.png" title="image-20220419103732990"></a></li></ol><h4 id="MapReduce-测试"><a href="#MapReduce-测试" class="headerlink" title="MapReduce 测试"></a>MapReduce 测试</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/module/hadoop-3.1.3</span><br><span class="line"><span class="meta">#</span><span class="bash"> 注意 /wcoutput 是结果输出目录，这个目录在 hdfs 上不能存在，程序会自己创建</span></span><br><span class="line">hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount /wcinput /wcoutput</span><br></pre></td></tr></table></figure><p>上 web 端查看，可以看到有一个 wordcount 任务在跑：<a target="_blank" rel="noopener external nofollow noreferrer" href="http://hadoop103:8088/cluster/apps/RUNNING">http://hadoop103:8088/cluster/apps/RUNNING</a></p><a href="/articles/62974551/aBCdEdd7C6image-20220419104420931.png" class="gallery-item"><img src="/articles/62974551/aBCdEdd7C6image-20220419104420931.png" title="image-20220419104420931"></a><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 执行日志</span></span><br><span class="line">2022-04-19 10:43:28,907 INFO client.RMProxy: Connecting to ResourceManager at hadoop103/192.168.3.103:8032</span><br><span class="line">2022-04-19 10:43:29,574 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/root/.staging/job_1650334953814_0001</span><br><span class="line">2022-04-19 10:43:29,713 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false</span><br><span class="line">2022-04-19 10:43:29,973 INFO input.FileInputFormat: Total input files to process : 1</span><br><span class="line">2022-04-19 10:43:30,023 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false</span><br><span class="line">2022-04-19 10:43:30,104 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false</span><br><span class="line">2022-04-19 10:43:30,155 INFO mapreduce.JobSubmitter: number of splits:1</span><br><span class="line">2022-04-19 10:43:30,326 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false</span><br><span class="line">2022-04-19 10:43:30,420 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1650334953814_0001</span><br><span class="line">2022-04-19 10:43:30,420 INFO mapreduce.JobSubmitter: Executing with tokens: []</span><br><span class="line">2022-04-19 10:43:30,700 INFO conf.Configuration: resource-types.xml not found</span><br><span class="line">2022-04-19 10:43:30,701 INFO resource.ResourceUtils: Unable to find &#x27;resource-types.xml&#x27;.</span><br><span class="line">2022-04-19 10:43:31,208 INFO impl.YarnClientImpl: Submitted application application_1650334953814_0001</span><br><span class="line">2022-04-19 10:43:31,279 INFO mapreduce.Job: The url to track the job: http://hadoop103:8088/proxy/application_1650334953814_0001/</span><br><span class="line">2022-04-19 10:43:31,280 INFO mapreduce.Job: Running job: job_1650334953814_0001</span><br><span class="line">2022-04-19 10:43:41,697 INFO mapreduce.Job: Job job_1650334953814_0001 running in uber mode : false</span><br><span class="line">2022-04-19 10:43:41,699 INFO mapreduce.Job:  map 0% reduce 0%</span><br><span class="line">2022-04-19 10:43:50,951 INFO mapreduce.Job:  map 100% reduce 0%</span><br><span class="line">2022-04-19 10:44:00,224 INFO mapreduce.Job:  map 100% reduce 100%</span><br><span class="line">2022-04-19 10:44:01,259 INFO mapreduce.Job: Job job_1650334953814_0001 completed successfully</span><br><span class="line">2022-04-19 10:44:01,402 INFO mapreduce.Job: Counters: 53</span><br><span class="line">        File System Counters</span><br><span class="line">                FILE: Number of bytes read=42</span><br><span class="line">                FILE: Number of bytes written=434299</span><br><span class="line">                FILE: Number of read operations=0</span><br><span class="line">                FILE: Number of large read operations=0</span><br><span class="line">                FILE: Number of write operations=0</span><br><span class="line">                HDFS: Number of bytes read=139</span><br><span class="line">                HDFS: Number of bytes written=24</span><br><span class="line">                HDFS: Number of read operations=8</span><br><span class="line">                HDFS: Number of large read operations=0</span><br><span class="line">                HDFS: Number of write operations=2</span><br><span class="line">        Job Counters</span><br><span class="line">                Launched map tasks=1</span><br><span class="line">                Launched reduce tasks=1</span><br><span class="line">                Data-local map tasks=1</span><br><span class="line">                Total time spent by all maps in occupied slots (ms)=25120</span><br><span class="line">                Total time spent by all reduces in occupied slots (ms)=22660</span><br><span class="line">                Total time spent by all map tasks (ms)=6280</span><br><span class="line">                Total time spent by all reduce tasks (ms)=5665</span><br><span class="line">                Total vcore-milliseconds taken by all map tasks=6280</span><br><span class="line">                Total vcore-milliseconds taken by all reduce tasks=5665</span><br><span class="line">                Total megabyte-milliseconds taken by all map tasks=25722880</span><br><span class="line">                Total megabyte-milliseconds taken by all reduce tasks=23203840</span><br><span class="line">        Map-Reduce Framework</span><br><span class="line">                Map input records=3</span><br><span class="line">                Map output records=6</span><br><span class="line">                Map output bytes=60</span><br><span class="line">                Map output materialized bytes=42</span><br><span class="line">                Input split bytes=103</span><br><span class="line">                Combine input records=6</span><br><span class="line">                Combine output records=3</span><br><span class="line">                Reduce input groups=3</span><br><span class="line">                Reduce shuffle bytes=42</span><br><span class="line">                Reduce input records=3</span><br><span class="line">                Reduce output records=3</span><br><span class="line">                Spilled Records=6</span><br><span class="line">                Shuffled Maps =1</span><br><span class="line">                Failed Shuffles=0</span><br><span class="line">                Merged Map outputs=1</span><br><span class="line">                GC time elapsed (ms)=306</span><br><span class="line">                CPU time spent (ms)=2120</span><br><span class="line">                Physical memory (bytes) snapshot=445448192</span><br><span class="line">                Virtual memory (bytes) snapshot=10477551616</span><br><span class="line">                Total committed heap usage (bytes)=394264576</span><br><span class="line">                Peak Map Physical memory (bytes)=275689472</span><br><span class="line">                Peak Map Virtual memory (bytes)=5234483200</span><br><span class="line">                Peak Reduce Physical memory (bytes)=169758720</span><br><span class="line">                Peak Reduce Virtual memory (bytes)=5243068416</span><br><span class="line">        Shuffle Errors</span><br><span class="line">                BAD_ID=0</span><br><span class="line">                CONNECTION=0</span><br><span class="line">                IO_ERROR=0</span><br><span class="line">                WRONG_LENGTH=0</span><br><span class="line">                WRONG_MAP=0</span><br><span class="line">                WRONG_REDUCE=0</span><br><span class="line">        File Input Format Counters</span><br><span class="line">                Bytes Read=36</span><br><span class="line">        File Output Format Counters</span><br><span class="line">                Bytes Written=24</span><br></pre></td></tr></table></figure><p>可以清楚的看到分为了 map 和 reduce 计算</p><p>到 HDFS 上查看计算结果：</p><a href="/articles/62974551/5d6A08d68dimage-20220419104623985.png" class="gallery-item"><img src="/articles/62974551/5d6A08d68dimage-20220419104623985.png" title="image-20220419104623985"></a><p>进入 wcoutput 可以看到已经词频统计完毕了，这个 SUCCESS 文件代表就是任务成功执行标志，没有其他意义，我们的结果文件在 part-r-00000 文件中</p><a href="/articles/62974551/1c7c1A14Acimage-20220419104755745.png" class="gallery-item"><img src="/articles/62974551/1c7c1A14Acimage-20220419104755745.png" title="image-20220419104755745"></a><h3 id="至此，集群已搭建完成"><a href="#至此，集群已搭建完成" class="headerlink" title="至此，集群已搭建完成"></a>至此，集群已搭建完成</h3></div><script src="https://cdn.jsdelivr.net/lightgallery.js/1.0.1/js/lightgallery.min.js"></script><script>var options;"undefined"!=typeof lightGallery&&(options={selector:".gallery-item"},lightGallery(document.getElementsByClassName(".article-gallery")[0],options))</script></div></article><div class="blog-post-comments"><div id="disqus_thread"><noscript>加载评论需要在浏览器启用 JavaScript 脚本支持。</noscript></div></div><div id="footer-post-container"><div id="footer-post"><div id="nav-footer" style="display:none"><ul><li><a href="/">首页</a></li><li><a href="/archives/">文章</a></li><li><a href="/categories/">分类</a></li><li><a href="/search/">搜索</a></li><li><a href="/about/">关于</a></li></ul></div><div id="toc-footer" style="display:none"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B4%E4%BD%93%E6%B5%81%E7%A8%8B"><span class="toc-number">1.</span> <span class="toc-text">整体流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E6%9D%BF%E6%9C%BA%E5%87%86%E5%A4%87"><span class="toc-number">2.</span> <span class="toc-text">模板机准备</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%85%8D%E7%BD%AE"><span class="toc-number">2.1.</span> <span class="toc-text">虚拟机配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E5%8C%BA%E9%85%8D%E7%BD%AE"><span class="toc-number">2.2.</span> <span class="toc-text">分区配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E5%8F%8A%E4%B8%BB%E6%9C%BA%E5%90%8D%E9%85%8D%E7%BD%AE"><span class="toc-number">2.3.</span> <span class="toc-text">网络及主机名配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#epel-release-%E5%AE%89%E8%A3%85"><span class="toc-number">2.4.</span> <span class="toc-text">epel-release 安装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B3%E9%97%AD%E9%98%B2%E7%81%AB%E5%A2%99"><span class="toc-number">2.5.</span> <span class="toc-text">关闭防火墙</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85%E7%9B%AE%E5%BD%95%E5%92%8C%E5%AE%89%E8%A3%85%E5%8C%85%E5%AD%98%E6%94%BE%E7%9B%AE%E5%BD%95"><span class="toc-number">2.6.</span> <span class="toc-text">创建软件安装目录和安装包存放目录</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%B8%E8%BD%BD%E8%99%9A%E6%8B%9F%E6%9C%BA%E8%87%AA%E5%B8%A6-JDK"><span class="toc-number">2.7.</span> <span class="toc-text">卸载虚拟机自带 JDK</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA"><span class="toc-number">3.</span> <span class="toc-text">集群搭建</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E6%A8%A1%E6%9D%BF%E6%9C%BA%E5%85%8B%E9%9A%86%E5%87%BA%E4%B8%89%E5%8F%B0%E6%9C%BA%E5%99%A8%E5%81%9A%E9%9B%86%E7%BE%A4"><span class="toc-number">3.1.</span> <span class="toc-text">使用模板机克隆出三台机器做集群</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9-ip-%E5%92%8C-hostname"><span class="toc-number">3.2.</span> <span class="toc-text">修改 ip 和 hostname</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE-hosts"><span class="toc-number">3.3.</span> <span class="toc-text">配置 hosts</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#JDK-%E5%AE%89%E8%A3%85"><span class="toc-number">3.4.</span> <span class="toc-text">JDK 安装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hadoop-%E5%AE%89%E8%A3%85"><span class="toc-number">3.5.</span> <span class="toc-text">Hadoop 安装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE-ssh-%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95"><span class="toc-number">3.6.</span> <span class="toc-text">配置 ssh 免密登录</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%96%E5%86%99-xsync-%E5%88%86%E5%8F%91%E8%84%9A%E6%9C%AC"><span class="toc-number">3.7.</span> <span class="toc-text">编写 xsync 分发脚本</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E5%8F%91%E5%B7%B2%E5%AE%89%E8%A3%85%E7%9A%84-JDK-%E5%92%8C-Hadoop"><span class="toc-number">3.8.</span> <span class="toc-text">分发已安装的 JDK 和 Hadoop</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E8%A7%84%E5%88%92"><span class="toc-number">3.9.</span> <span class="toc-text">集群部署规划</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE-Hadoop-%E7%9B%B8%E5%85%B3%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">3.10.</span> <span class="toc-text">配置 Hadoop 相关配置文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E5%8F%91-%E5%90%8C%E6%AD%A5-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">3.11.</span> <span class="toc-text">分发&#x2F;同步 配置文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9D%E5%A7%8B%E5%8C%96%E9%9B%86%E7%BE%A4"><span class="toc-number">3.12.</span> <span class="toc-text">初始化集群</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8-HDFS-%E5%8F%8A-YARN"><span class="toc-number">3.13.</span> <span class="toc-text">启动 HDFS 及 YARN</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%AA%8C%E8%AF%81%E5%8F%8A%E6%B5%8B%E8%AF%95"><span class="toc-number">3.14.</span> <span class="toc-text">验证及测试</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%80%9A%E8%BF%87%E6%9F%A5%E7%9C%8B%E5%90%8E%E5%8F%B0%E8%BF%9B%E7%A8%8B%E9%AA%8C%E8%AF%81-HDFS-%E5%8F%8A-YARN-%E6%98%AF%E5%90%A6%E6%88%90%E5%8A%9F%E5%90%AF%E5%8A%A8"><span class="toc-number">3.14.1.</span> <span class="toc-text">通过查看后台进程验证 HDFS 及 YARN 是否成功启动</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8E%BB-web-%E7%95%8C%E9%9D%A2%E6%9F%A5%E7%9C%8B"><span class="toc-number">3.14.2.</span> <span class="toc-text">去 web 界面查看</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6%E5%88%B0-HDFS-%E6%B5%8B%E8%AF%95"><span class="toc-number">3.14.3.</span> <span class="toc-text">上传文件到 HDFS 测试</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#MapReduce-%E6%B5%8B%E8%AF%95"><span class="toc-number">3.14.4.</span> <span class="toc-text">MapReduce 测试</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%B3%E6%AD%A4%EF%BC%8C%E9%9B%86%E7%BE%A4%E5%B7%B2%E6%90%AD%E5%BB%BA%E5%AE%8C%E6%88%90"><span class="toc-number">3.15.</span> <span class="toc-text">至此，集群已搭建完成</span></a></li></ol></li></ol></div><div id="share-footer" style="display:none"><ul><li><a class="icon" target="_blank" rel="noopener external nofollow noreferrer" href="http://www.facebook.com/sharer.php?u=https://www.powercheng.fun/articles/62974551/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li><li><a class="icon" target="_blank" rel="noopener external nofollow noreferrer" href="https://twitter.com/share?url=https://www.powercheng.fun/articles/62974551/&text=Hadoop集群搭建"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li><li><a class="icon" target="_blank" rel="noopener external nofollow noreferrer" href="http://www.linkedin.com/shareArticle?url=https://www.powercheng.fun/articles/62974551/&title=Hadoop集群搭建"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li><li><a class="icon" target="_blank" rel="noopener external nofollow noreferrer" href="https://pinterest.com/pin/create/bookmarklet/?url=https://www.powercheng.fun/articles/62974551/&is_video=false&description=Hadoop集群搭建"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li><li><a class="icon" href="mailto:?subject=Hadoop集群搭建&body=Check out this article: https://www.powercheng.fun/articles/62974551/" rel="external nofollow noreferrer"><i class="fa-solid fa-envelope fa-lg" aria-hidden="true"></i></a></li><li><a class="icon" target="_blank" rel="noopener external nofollow noreferrer" href="https://getpocket.com/save?url=https://www.powercheng.fun/articles/62974551/&title=Hadoop集群搭建"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li><li><a class="icon" target="_blank" rel="noopener external nofollow noreferrer" href="http://reddit.com/submit?url=https://www.powercheng.fun/articles/62974551/&title=Hadoop集群搭建"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li><li><a class="icon" target="_blank" rel="noopener external nofollow noreferrer" href="http://www.stumbleupon.com/submit?url=https://www.powercheng.fun/articles/62974551/&title=Hadoop集群搭建"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li><li><a class="icon" target="_blank" rel="noopener external nofollow noreferrer" href="http://digg.com/submit?url=https://www.powercheng.fun/articles/62974551/&title=Hadoop集群搭建"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li><li><a class="icon" target="_blank" href="http://www.tumblr.com/share/link?url=https://www.powercheng.fun/articles/62974551/&name=Hadoop集群搭建&description=&lt;link rel=&#34;stylesheet&#34; type=&#34;text/css&#34; href=&#34;https://cdn.jsdelivr.net/lightgallery.js/1.0.1/css/lightgallery.min.css&#34; /&gt;&lt;div class=&#34;.article-gallery&#34;&gt;&lt;p&gt;本地虚拟环境搭建 Hadoop 集群，是集群搭建的过程记录&lt;/p&gt;"><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li><li><a class="icon" target="_blank" rel="noopener external nofollow noreferrer" href="https://news.ycombinator.com/submitlink?u=https://www.powercheng.fun/articles/62974551/&t=Hadoop集群搭建"><i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i></a></li></ul></div><div id="actions-footer"><a id="menu" class="icon" href="#" onclick='return $("#nav-footer").toggle(),!1'><i class="fa-solid fa-bars fa-lg" aria-hidden="true"></i> 菜单</a> <a id="toc" class="icon" href="#" onclick='return $("#toc-footer").toggle(),!1'><i class="fa-solid fa-list fa-lg" aria-hidden="true"></i> 目录</a> <a id="share" class="icon" href="#" onclick='return $("#share-footer").toggle(),!1'><i class="fa-solid fa-share-alt fa-lg" aria-hidden="true"></i> 分享</a> <a id="top" style="display:none" class="icon" href="#" onclick='$("html, body").animate({scrollTop:0},"fast")'><i class="fa-solid fa-chevron-up fa-lg" aria-hidden="true"></i> 返回顶部</a></div></div></div><footer id="footer"><div class="footer-left">Copyright &copy; 2021-2025 Caiden Hou</div><div class="footer-right"><nav><ul><li><a href="/">首页</a></li><li><a href="/archives/">文章</a></li><li><a href="/categories/">分类</a></li><li><a href="/search/">搜索</a></li><li><a href="/about/">关于</a></li></ul></nav></div></footer></div><link rel="preload" href="/lib/font-awesome/css/all.min.css" as="style" onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel="stylesheet" href="/lib/font-awesome/css/all.min.css"></noscript><script src="/lib/jquery/jquery.min.js"></script><script src="/lib/clipboard/clipboard.min.js"></script><script type="text/javascript">$(function(){$(".highlight table").before('<span class="btn-copy tooltipped tooltipped-sw" aria-label="复制到粘贴板！"><i class="fa-regular fa-clone"></i></span>'),new ClipboardJS(".btn-copy",{text:function(e){return Array.from(e.nextElementSibling.querySelectorAll(".code")).reduce((e,t)=>e+t.innerText+"\n","")}}).on("success",function(e){e.trigger.setAttribute("aria-label","复制成功！"),e.clearSelection()})})</script><script src="/js/main.js"></script><script type="text/javascript">var disqus_shortname="caidens-blog";!function(){var e=document.createElement("script");e.type="text/javascript",e.async=!0,e.src="//"+disqus_shortname+".disqus.com/embed.js",(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(e)}()</script></body></html>